knitr::opts_chunk$set(echo = TRUE)
require(caret)
require(recipes)
require(finalfit)
require(glmnet)
library(dplyr)
str(stuperform)
#add a column for ID
stuperform <- mutate(studentperform, id = row_number())
studentperform <- read.csv("C:/Users/makay/OneDrive/Desktop/Data Science/Machine Learning/654finalproject/data/studentdata.csv",header=TRUE)
#add a column for ID
stuperform <- mutate(studentperform, id = row_number())
str(stuperform)
outcome <- c('Class')
id <- c('id')
categorical <- c('Gender',
'Nationality',
'PlaceofBirth',
'StageID',
'GradeID',
'SectionID',
'Topic',
'Semester',
'Relation',
'ParentAnsweringSurvey',
'ParentschoolSatisfaction',
'StudentAbsenceDays')
numeric <- c('raisedhands',
'VisITedResources',
'AnnouncementsView',
'Discussion')
for(i in categorical){
stuperform[,i] <- as.factor(stuperform[,i])
}
student_blueprint <- recipe(x = stuperform,
vars = c(outcome, id, categorical, numeric),
roles = c('outcome', 'id', rep('predictor', 16))) %>%
step_indicate_na(all_of(categorical), all_of(numeric)) %>%
step_zv(all_numeric()) %>%
step_impute_mean(all_of(numeric)) %>%
step_impute_mode(all_of(categorical)) %>%
step_ns(all_of(numeric), deg_free = 3) %>%
step_normalize(paste0(numeric, '_ns_1'),
paste0(numeric, '_ns_2'),
paste0(numeric, '_ns_3')) %>%
step_dummy(all_of(categorical), one_hot = TRUE)
student_blueprint
prepare <- prep(student_blueprint,
training = stuperform)
baked_student <- bake(prepare, new_data = stuperform)
View(stuperform)
missing <- ff_glimpse(stuperform)$Continuous
head(missing)
#set the seed. create test and traing dataset where training data is 80% and test is 20%
set.seed(12092021)
loc      <- sample(1:nrow(stuperform), round(nrow(stuperform) * 0.8))
student_train  <- stuperform[loc, ]
student_test  <- stuperform[-loc, ]
student_train = student_train[sample(nrow(student_train)),]
folds = cut(seq(1,nrow(student_train)),breaks=10,labels=FALSE)
my.indices <- vector('list',10)
for(i in 1:10){
my.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method = "cv",
index  = my.indices)
caret_mod <- caret::train(student_blueprint,
data      = student_train,
method    = "lm",
trControl = cv)
View(baked_student)
oregon <- read.csv('https://raw.githubusercontent.com/uo-datasci-specialization/c4-ml-fall-2021/main/content/post/hw2/data/hw1_oregon_final.csv',header=TRUE)
View(oregon)
outcome <- 'score'
id      <- 'id'
categorical <- c('sex','ethnic_cd','tst_bnch','migrant_ed_fg','ind_ed_fg',
'sp_ed_fg','tag_ed_fg','econ_dsvntg','stay_in_dist',
'stay_in_schl','dist_sped','trgt_assist_fg',
'ayp_dist_partic','ayp_schl_partic','ayp_dist_prfrm',
'ayp_schl_prfrm','rc_dist_partic','rc_schl_partic',
'rc_dist_prfrm','rc_schl_prfrm','grp_rpt_dist_partic',
'grp_rpt_schl_partic','grp_rpt_dist_prfrm',
'grp_rpt_schl_prfrm')
numeric <- c('enrl_grd')
cyclic <- c('date','month')
blueprint_oregon <- recipe(x     = oregon,
vars  = c(outcome,categorical,numeric,cyclic),
roles = c('outcome',rep('predictor',27))) %>%
step_indicate_na(all_of(categorical),all_of(numeric)) %>%
step_zv(all_numeric()) %>%
step_impute_mean(all_of(numeric)) %>%
step_impute_mode(all_of(categorical)) %>%
step_harmonic('date',frequency=1,cycle_size=31,role='predictor') %>%
step_harmonic('month',frequency=1,cycle_size=12,role='predictor') %>%
step_ns('enrl_grd',deg_free=3) %>%
step_normalize(c(paste0(numeric,'_ns_1'),paste0(numeric,'_ns_2'),paste0(numeric,'_ns_3'))) %>%
step_normalize(c("date_sin_1","date_cos_1","month_sin_1","month_cos_1")) %>%
step_dummy(all_of(categorical),one_hot=TRUE) %>%
step_rm(c('date','month'))
View(blueprint_oregon)
stuperform[stuform == "L"] <- 0
stuperform[stuperform == "L"] <- 0
View(stuperform)
5
stuperform[stuperform == "M"] <- 5
stuperform[stuperform == "M"] <- 5
stuperform[stuperform == "H"] <- 10
str(stuperform)
knitr::opts_chunk$set(echo = TRUE)
require(caret)
require(recipes)
require(finalfit)
require(glmnet)
library(dplyr)
studentperform <- read.csv("C:/Users/makay/OneDrive/Desktop/Data Science/Machine Learning/654finalproject/data/studentdata.csv",header=TRUE)
#add a column for ID
stuperform <- mutate(studentperform, id = row_number())
stuperform[stuperform == "L"] <- 0
stuperform[stuperform == "M"] <- 5
stuperform[stuperform == "H"] <- 10
str(stuperform)
outcome <- c('Class')
id <- c('id')
categorical <- c('Gender',
'Nationality',
'PlaceofBirth',
'StageID',
'GradeID',
'SectionID',
'Topic',
'Semester',
'Relation',
'ParentAnsweringSurvey',
'ParentschoolSatisfaction',
'StudentAbsenceDays')
numeric <- c('raisedhands',
'VisITedResources',
'AnnouncementsView',
'Discussion')
for(i in categorical){
stuperform[,i] <- as.factor(stuperform[,i])
}
student_blueprint <- recipe(x = stuperform,
vars = c(outcome, id, categorical, numeric),
roles = c('outcome', 'id', rep('predictor', 16))) %>%
step_indicate_na(all_of(categorical), all_of(numeric)) %>%
step_zv(all_numeric()) %>%
step_impute_mean(all_of(numeric)) %>%
step_impute_mode(all_of(categorical)) %>%
step_ns(all_of(numeric), deg_free = 3) %>%
step_normalize(paste0(numeric, '_ns_1'),
paste0(numeric, '_ns_2'),
paste0(numeric, '_ns_3')) %>%
step_dummy(all_of(categorical), one_hot = TRUE)
student_blueprint
prepare <- prep(student_blueprint,
training = stuperform)
baked_student <- bake(prepare, new_data = stuperform)
#evaluate for missing variables
missing <- ff_glimpse(stuperform)$Continuous
head(missing)
#no missing variables present to remove
#set the seed. create test and traing dataset where training data is 80% and test is 20%
set.seed(12092021)
loc      <- sample(1:nrow(stuperform), round(nrow(stuperform) * 0.8))
student_train  <- stuperform[loc, ]
student_test  <- stuperform[-loc, ]
# Randomly shuffle the data
student_train = student_train[sample(nrow(student_train)),]
# Create 10 folds with equal size
folds = cut(seq(1,nrow(student_train)),breaks=10,labels=FALSE)
# Create the list for each fold
my.indices <- vector('list',10)
for(i in 1:10){
my.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method = "cv",
index  = my.indices)
caret_mod <- caret::train(student_blueprint,
data      = student_train,
method    = "lm",
trControl = cv)
caret_mod$bestTune
predicted_te <- predict(caret_mod, student_test)
nr_rsq_te <- cor(student_test$Class,predicted_te)^2
nr_rsq_te
#
nr_mae_te <- mean(abs(student_test$Class - predicted_te))
nr_mae_te
#
nr_rmse_te <- sqrt(mean((student_test$Class - predicted_te)^2))
nr_rmse_te
#
grid <- data.frame(alpha = 0, lambda = seq(0.01,3,.01))
grid
ridge <- caret::train(student_blueprint,
data      = student_train,
method    = "glmnet",
trControl = cv,
tuneGrid  = grid)
ridge$bestTune
predict_te_ridge <- predict(ridge, student_test)
r_rsq_te <- cor(student_test$Class,predict_te_ridge)^2
View(student_test)
str(stuperform)
as.numeric(stuperform$Class)
str(stuperform)
sapply(stuperform$Class)
str(stuperform)
stuperform$Class <- as.numeric(stuperform$Class)
str(stuperform)
knitr::opts_chunk$set(echo = TRUE)
require(caret)
require(recipes)
require(finalfit)
require(glmnet)
library(dplyr)
studentperform <- read.csv("C:/Users/makay/OneDrive/Desktop/Data Science/Machine Learning/654finalproject/data/studentdata.csv",header=TRUE)
#add a column for ID
stuperform <- mutate(studentperform, id = row_number())
#modify Class column to represent numeric values rather than characters
stuperform[stuperform == "L"] <- 0
stuperform[stuperform == "M"] <- 5
stuperform[stuperform == "H"] <- 10
stuperform$Class <- as.numeric(stuperform$Class)
str(stuperform)
outcome <- c('Class')
id <- c('id')
categorical <- c('Gender',
'Nationality',
'PlaceofBirth',
'StageID',
'GradeID',
'SectionID',
'Topic',
'Semester',
'Relation',
'ParentAnsweringSurvey',
'ParentschoolSatisfaction',
'StudentAbsenceDays')
numeric <- c('raisedhands',
'VisITedResources',
'AnnouncementsView',
'Discussion')
for(i in categorical){
stuperform[,i] <- as.factor(stuperform[,i])
}
student_blueprint <- recipe(x = stuperform,
vars = c(outcome, id, categorical, numeric),
roles = c('outcome', 'id', rep('predictor', 16))) %>%
step_indicate_na(all_of(categorical), all_of(numeric)) %>%
step_zv(all_numeric()) %>%
step_impute_mean(all_of(numeric)) %>%
step_impute_mode(all_of(categorical)) %>%
step_ns(all_of(numeric), deg_free = 3) %>%
step_normalize(paste0(numeric, '_ns_1'),
paste0(numeric, '_ns_2'),
paste0(numeric, '_ns_3')) %>%
step_dummy(all_of(categorical), one_hot = TRUE)
student_blueprint
prepare <- prep(student_blueprint,
training = stuperform)
baked_student <- bake(prepare, new_data = stuperform)
#evaluate for missing variables
missing <- ff_glimpse(stuperform)$Continuous
head(missing)
#no missing variables present to remove
#set the seed. create test and traing dataset where training data is 80% and test is 20%
set.seed(12092021)
loc      <- sample(1:nrow(stuperform), round(nrow(stuperform) * 0.8))
student_train  <- stuperform[loc, ]
student_test  <- stuperform[-loc, ]
# Randomly shuffle the data
student_train = student_train[sample(nrow(student_train)),]
# Create 10 folds with equal size
folds = cut(seq(1,nrow(student_train)),breaks=10,labels=FALSE)
# Create the list for each fold
my.indices <- vector('list',10)
for(i in 1:10){
my.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method = "cv",
index  = my.indices)
caret_mod <- caret::train(student_blueprint,
data      = student_train,
method    = "lm",
trControl = cv)
caret_mod$bestTune
predicted_te <- predict(caret_mod, student_test)
nr_rsq_te <- cor(student_test$Class,predicted_te)^2
nr_rsq_te
#
nr_mae_te <- mean(abs(student_test$Class - predicted_te))
nr_mae_te
#
nr_rmse_te <- sqrt(mean((student_test$Class - predicted_te)^2))
nr_rmse_te
#
#create a grid
grid <- data.frame(alpha = 0, lambda = seq(0.01,3,.01))
grid
# Train the model
ridge <- caret::train(student_blueprint,
data      = student_train,
method    = "glmnet",
trControl = cv,
tuneGrid  = grid)
ridge$bestTune
predict_te_ridge <- predict(ridge, student_test)
r_rsq_te <- cor(student_test$Class,predict_te_ridge)^2
r_rsq_te
# 0.4062631
r_mae_te <- mean(abs(ordata_test$score - predict_te_ridge))
r_mae_te
# 69.35026
r_rmse_te <- sqrt(mean((ordata_test$score - predict_te_ridge)^2))
r_rmse_te
# 89.12628
r_rsq_te <- cor(student_test$Class,predict_te_ridge)^2
r_rsq_te
# 0.679095
r_mae_te <- mean(abs(student_test$Class - predict_te_ridge))
r_mae_te
# 1.678192
r_rmse_te <- sqrt(mean((student_test$Class - predict_te_ridge)^2))
r_rmse_te
#determine the optimal lambda
#define response variable
y <- stuperform$Class
#define matrix of predictor variables
x <- data.matrix(stuperform[, c('Gender',
'Nationality',
'PlaceofBirth',
'StageID',
'GradeID',
'SectionID',
'Topic',
'Semester',
'Relation',
'ParentAnsweringSurvey',
'ParentschoolSatisfaction',
'StudentAbsenceDays',
'raisedhands',
'VisITedResources',
'AnnouncementsView',
'Discussion')])
#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(x, y, alpha = 0)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
#produce plot of test MSE by lambda value
plot(cv_model)
#create a grid
grid <- data.frame(alpha = 0, lambda = 0.3673767)
ridge <- caret::train(student_blueprint,
data      = student_train,
method    = "glmnet",
trControl = cv,
tuneGrid  = grid)
ridge$bestTune
predict_te_ridge <- predict(ridge, student_test)
r_rsq_te <- cor(student_test$Class,predict_te_ridge)^2
r_rsq_te
# 0.6714214
r_mae_te <- mean(abs(student_test$Class - predict_te_ridge))
r_mae_te
# 1.707019
r_rmse_te <- sqrt(mean((student_test$Class - predict_te_ridge)^2))
r_rmse_te
grid2 <- data.frame(alpha = 1, lambda = 0.3673767)
grid2
lasso <- caret::train(student_blueprint,
data      = student_train,
method    = "glmnet",
trControl = cv,
tuneGrid  = grid2)
lasso$bestTune
#getting errors in this section
predict_te_lasso<- predict(lasso, student_test)
l_rsq_te <- cor(student_test$Class,predict_te_lasso)^2
l_rsq_te
#0.6529293
l_mae_te <- mean(abs(student_test$Class - predict_te_lasso))
l_mae_te
# 1.886536
l_rmse_te <- sqrt(mean((student_test$Class - predict_te_lasso)^2))
l_rmse_te
# Cross validation settings
student_train = student_train[sample(nrow(student_train)),]
folds = cut(seq(1,nrow(student_train)),breaks=10,labels=FALSE)
my.indices2 <- vector('list',10)
for(i in 1:10){
my.indices2[[i]] <- which(folds!=i)
}
my.indices <- vector('list',10)
for(i in 1:10){
my.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method = "none",
index  = my.indices)
cv <- trainControl(method = "cv",
index  = my.indices)
grid <- expand.grid(mtry = 16,splitrule='variance',min.node.size=2)
student_baggedtrees <- caret::train(student_blueprint,
data      = student_train,
method    = 'ranger',
trControl = cv,
tuneGrid  = grid,
num.trees = 100,
max.depth = 60)
student_baggedtrees <- caret::train(student_blueprint,
data      = student_train,
method    = 'ranger',
trControl = cv,
tuneGrid  = grid,
num.trees = 100,
max.depth = 60)
student_baggedtrees$times
student_baggedtrees <- caret::train(student_blueprint,
data      = student_train,
method    = 'ranger',
trControl = cv,
tuneGrid  = grid,
num.trees = 100,
max.depth = 10)
student_baggedtrees$times
#checking bagged tree model on the test dataset
student_predict_test <- predict(student_baggedtrees, student_test)
#calculate RMSE for bagged tree model
bag_rmse <- sqrt(mean((student_test$Class - student_predict_test)^2))
bag_rmse
#calculate MAE for bagged tree model
studentpredicted_te <- predict(student_baggedtrees, student_test)
#MAE
bag_mae <- mean(abs(student_test$Class - studentpredicted_te))
bag_mae
#calculate rsqd for bagged tree model
bag_rsqd <- cor(student_test$Class,studentpredicted_te)^2
bag_rsqd
# Cross validation settings
student_train = student_train[sample(nrow(student_train)),]
folds = cut(seq(1,nrow(student_train)),breaks=10,labels=FALSE)
my.indices <- vector('list',10)
for(i in 1:10){
my.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method = "cv",
index  = my.indices)
rgrid <- expand.grid(mtry = 16,splitrule='variance',min.node.size=2)
student_rforest <- caret::train(student_blueprint,
data      = student_train,
method    = 'ranger',
trControl = cv,
tuneGrid  = grid,
num.trees = 100,
max.depth = 10)
student_rforest$times
cv <- trainControl(method = "none",
index  = my.indices)
student_rforest <- caret::train(student_blueprint,
data      = student_train,
method    = 'ranger',
trControl = cv,
tuneGrid  = grid,
num.trees = 100,
max.depth = 10)
student_rforest$times
cv <- trainControl(method = "cv",
index  = my.indices)
student_rforest <- caret::train(student_blueprint,
data      = student_train,
method    = 'ranger',
trControl = cv,
tuneGrid  = grid,
num.trees = 100,
max.depth = 10)
#checking random forest model on the test dataset
rpredict_te <- predict(student_rforest, student_test)
# RMSE for random forest model
ran_rmse <- sqrt(mean((student_test$Class - rpredict_te)^2))
ran_rmse
#calculate MAE for random tree model
test_predict <- predict(student_baggedtrees, student_test)
#MAE
ran_mae <- mean(abs(student_test$Class - test_predict))
ran_mae
#calculate rsqd for bagged tree model
ran_rsqd <- cor(student_test$Class, test_predict)^2
ran_rsqd
ridgereg <- data.frame(Model = c("Linear Regression with Ridge Penalty"),
RMSE = c(r_rmse_te),
MAE = c(r_mae_te),
Rsq = c(r_rsq_te))
lassoreg <- data.frame(Model = c("Linear Regression with Lasso Penalty"),
RMSE = c(l_rmse_te),
MAE = c(l_mae_te),
Rsq = c(l_rsq_te))
ranmod <- data.frame(Model = c("Random Forest Model"),
RMSE = c(ran_rmse),
MAE = c(ran_mae),
Rsq = c(ran_rsqd))
#Final Table
ModEvalTable <- rbind(ridgereg, lassoreg, ranmod)
ModEvalTable
